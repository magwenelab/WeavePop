# =================================================================================================
#   Check minimal version
# =================================================================================================

from snakemake.utils import min_version
import sys
import os

min_version("8.2.1")

# =================================================================================================
#   Setup config file
# =================================================================================================

if not config:
    configfile: "config/config.yaml"

# =================================================================================================
#   Save stdout and stderr to log file
# =================================================================================================

if config["output_directory"]:
    os.makedirs(config["output_directory"], exist_ok=True)
    log_file_path = config["output_directory"] + "/fungalpop.log"
else:
    log_file_path = "fungalpop.log"

if os.path.exists(log_file_path):
    base, ext = os.path.splitext(log_file_path)
    counter = 1
    new_log_file_path = f"{base}_{counter}{ext}"
    while os.path.exists(new_log_file_path):
        counter += 1
        new_log_file_path = f"{base}_{counter}{ext}"
    log_file_path = new_log_file_path

sys.stdout = open(log_file_path, "a")
sys.stderr = sys.stdout

# =================================================================================================
#   Define names of directories
# =================================================================================================

SAMPLES_DIR_NAME = "01.Samples"
DATASET_DIR_NAME = "02.Dataset"
REFS_DIR_NAME = "03.References"
INTDIR_NAME = "04.Intermediate_files"
TEMPDIR_NAME = "04.Temporary_files"

# =================================================================================================
#   Load rules
# =================================================================================================

# ------------------Analysis workflow--------------------------------------------------------------
if config["workflow"] == "analysis":

    include: "rules/common.smk"
    include: "rules/snippy.smk"
    include: "rules/quality_filter.smk"
    include: "rules/annotation.smk"
    include: "rules/database.smk"

    # ------------------Reference annotation rules-------------------------------------------------
    if config["annotate_references"]["activate"]:

        include: "rules/references_annotate.smk"

    if not config["annotate_references"]["activate"]:

        include: "rules/references_no_annotate.smk"


    # ------------------Module rules---------------------------------------------------------------
    if config["database"]["activate"]:

        include: "rules/cnv.smk"
        include: "rules/snpeff.smk"
        include: "rules/depth_quality_features.smk"
        if config["cnv"]["repeats"]["use_container"]:
            include: "rules/repeatmasker_containers.smk"
        else:
            include: "rules/repeatmasker.smk"


    else:

        if config["cnv"]["activate"] or config["plotting"]["activate"]:

            include: "rules/cnv.smk"
            if config["cnv"]["repeats"]["use_container"]:
                include: "rules/repeatmasker_containers.smk"
            else:
                include: "rules/repeatmasker.smk"

        if config["depth_quality_features"]["activate"] or config["plotting"]["activate"]:

            include: "rules/depth_quality_features.smk"

        if config["snpeff"]["activate"]:

            include: "rules/snpeff.smk"
    
    if config["plotting"]["activate"]:

        include: "rules/plots.smk"
        include: "rules/plots_dataset.smk"


# ------------------Join datasets workflow---------------------------------------------------------
elif config["workflow"] == "join_datasets":

    include: "rules/common_join_datasets.smk"
    include: "rules/join_datasets.smk"

# ------------------No workflow selected message----------------------------------------------------
else:
    print("Workflow must be one of 'analysis' or 'join_datasets'.", flush=True)
    print("Check the spelling in the config/config.yaml file.", flush=True)
    print("Exiting...", flush=True)
    exit(1)

# =================================================================================================
#   On success messages
# =================================================================================================

onsuccess:
    print("                                   ", flush=True)
    print(" _           _   _      _   _   _  ", flush=True)
    print("|_ | | |\\ | |_  |_| |  |_| | | |_|", flush=True)
    print("|  |_| | \\| |_| | | |_ |   |_| |  ", flush=True)
    print("                                   ", flush=True)
    print("                                   ", flush=True)
    if config["workflow"] == "analysis":
        print("The analysis workflow finished successfully!", flush=True)
        original_metadata = UNFILT_SAMPLE_TABLE
        filtered_metadata = pd.read_csv(rules.quality_filter.output.metadata, header=0)
        if original_metadata["sample"].nunique() == filtered_metadata["sample"].nunique():
            print("All samples passed the quality filter.", flush=True)
        else:
            print(
                f"The quality filter removed "
                f"{original_metadata['sample'].nunique()- filtered_metadata['sample'].nunique()} "
                f"samples. See 04.Intermediate_files/02.Dataset/depth_quality/"
                f"unfiltered_mapping_stats.tsv to check the quality warning of the removed samples.",
                flush=True,
            )
    elif config["workflow"] == "join_datasets":
        print("The join datasets workflow finished successfully!", flush=True)
    print("                                   ", flush=True)
    print("Enjoy science!", flush=True)

# =================================================================================================
#   On error messages
# =================================================================================================

onerror:
    print("                                   ", flush=True)
    print(" _           _   _      _   _   _  ", flush=True)
    print("|_ | | |\\ | |_  |_| |  |_| | | |_|", flush=True)
    print("|  |_| | \\| |_| | | |_ |   |_| |  ", flush=True)
    print("                                   ", flush=True)
    print("                                   ", flush=True)
    print("An error occurred during the workflow execution.", flush=True)
    print("Above, find the rule that failed and check its log file for error details.", flush=True)
    print("                                   ", flush=True)
    print("Exiting...", flush=True)
    exit(1)

# =================================================================================================
#   Define final output
# =================================================================================================

if config["workflow"] == "analysis":

    rule all:
        input:
            get_unfiltered_output(),
            get_filtered_output(),
            get_dataset_output(),

elif config["workflow"] == "join_datasets":

    rule all:
        input:
            get_final_output(),
