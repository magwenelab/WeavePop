# =================================================================================================
#   Check minimal version
# =================================================================================================

from snakemake.utils import min_version

min_version("8.2.1")

# =================================================================================================
#   Setup config file
# =================================================================================================


configfile: "config/config.yaml"


# =================================================================================================
#   Define names of directories
# =================================================================================================

SAMPLES_DIR_NAME = "01.Samples"
DATASET_DIR_NAME = "02.Dataset"
REFS_DIR_NAME = "03.References"
INTDIR_NAME = "04.Intermediate_files"
TEMPDIR_NAME = "04.Temporary_files"

# =================================================================================================
#   Load rules
# =================================================================================================

# ------------------Analysis workflow--------------------------------------------------------------
if config["workflow"] == "analysis":

    include: "rules/common.smk"
    include: "rules/snippy.smk"
    include: "rules/quality_filter.smk"
    include: "rules/annotation.smk"
    include: "rules/database.smk"

    # ------------------Reference annotation rules-------------------------------------------------
    if config["annotate_references"]["activate"]:

        include: "rules/references.smk"

        if config["plotting"]["activate"]:

            include: "rules/unmapped_main_ref.smk"

    if not config["annotate_references"]["activate"]:

        include: "rules/lineage_gffs.smk"

    # if config["plotting"]["activate"]:
    #     include: "rules/unmapped_per_lineage.smk"

    # ------------------Module rules---------------------------------------------------------------
    if config["plotting"]["activate"]:

        include: "rules/plots.smk"
        include: "rules/dataset_plots.smk"

    if config["cnv"]["activate"]:

        include: "rules/cnv.smk"
        include: "rules/repeatmasker.smk"

    if config["genes_mapq_depth"]["activate"]:

        include: "rules/genes_mapq_depth.smk"

    if config["snpeff"]["activate"]:

        include: "rules/snps.smk"

    if config["database"]["activate"]:

        include: "rules/cnv.smk"
        include: "rules/repeatmasker.smk"
        include: "rules/snps.smk"
        include: "rules/genes_mapq_depth.smk"


# ------------------Join datasets workflow---------------------------------------------------------
elif config["workflow"] == "join_datasets":

    include: "rules/common_join_datasets.smk"
    include: "rules/join_datasets.smk"


# =================================================================================================
#   Onstart checks
# =================================================================================================


onstart:
    print("Checking input files...", flush=True)
    try:
        sample_table = pd.read_csv(config["samples"], header=0)
        chrom_names = pd.read_csv(
            config["chromosomes"], header=0, names=["lineage", "accession", "chromosome"]
        )
        if chrom_names.isnull().values.any():
            raise ValueError("Chromosome names file has missing values.")
        if set(sample_table["lineage"].unique()) == set(chrom_names["lineage"].unique()):
            print("All lineages are in the chromosome names file.", flush=True)
        else:
            raise ValueError("Lineages in metadata and chromosome names file do not match.")

        chromosome_ids = []
        reference_dir = config["references"]["directory"]

        for lineage in chrom_names["lineage"].unique():
            ref_file = Path(reference_dir) / f"{lineage}.fasta"
            if ref_file.exists():
                for chrom in chrom_names[chrom_names["lineage"] == lineage]["accession"]:
                    with open(ref_file) as f:
                        seq_ids = [
                            line.strip().split()[0][1:] for line in f if line.startswith(">")
                        ]
                        if chrom not in seq_ids:
                            raise ValueError(
                                f"Chromosome {chrom} not found in reference {ref_file}"
                            )
            else:
                raise ValueError(f"Reference {ref_file} not found")

    except Exception as e:
        print("Error in input files:", flush=True)
        print(e)
        print("Exiting...", flush=True)
        exit(1)
    else:
        print("Input files are good! Starting workflow...", flush=True)


onsuccess:
    original_metadata = pd.read_csv(UNFILT_SAMPLE_FILE, header=0)
    filtered_metadata = pd.read_csv(rules.quality_filter.output.metadata, header=0)
    if original_metadata["sample"].nunique() == filtered_metadata["sample"].nunique():
        print("All samples passed the quality filter.", flush=True)
    else:
        print(
            f"The quality filter removed "
            f"{original_metadata['sample'].nunique()- filtered_metadata['sample'].nunique()} "
            f"samples. See 04.Intermediate_files/02.Dataset/depth_quality/"
            f"unfiltered_mapping_stats.tsv to check the quality warning of the removed samples.",
            flush=True,
        )


# =================================================================================================
#   Define final output
# =================================================================================================

if config["workflow"] == "analysis":

    rule all:
        input:
            get_unfiltered_output(),
            get_filtered_output(),
            get_dataset_output(),

elif config["workflow"] == "join_datasets":

    rule all:
        input:
            get_final_output(),
